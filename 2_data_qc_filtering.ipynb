{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Quality Control Filtering\n",
    "\n",
    "*Date: August 1, 2023*  \n",
    "*Author: Alicia Larsen*     \n",
    "*Institution: The Research Institute of Sweden (RISE)*   \n",
    "*Contact: alicia.hh.larsen@gmail.com*  \n",
    "\n",
    "This is the 3rd notebook of 7, in the series \"RISE Wildfire Prediction Using Machine Learning\"\n",
    "\n",
    "##### Keywords: LST, LSR, Fire detection, MODIS, Python\n",
    "\n",
    "## Reference\n",
    "This notebook is based on the procedures in the notebook found on this [link](https://github.com/ornldaac/modis_restservice_qc_filter_Python/blob/master/modis_restservice_qc_filter_Python.ipynb). This notebook can also be found in /initial-eda/data-procurement/reference-notebook/download-modis-data-example-notebook.ipynb, on github.com:larsenalicia/RISE-wildfire-prediction.git\n",
    "\n",
    "## Overview\n",
    "Some pixels are missing, others have bad quality due to clouds or other factors. This notebook will filter out bad-quality data points.\n",
    "\n",
    "## Prerequisites: \n",
    "\n",
    "* Python 2 or 3   \n",
    "* Libraries: requests, json, datetime, pandas, numpy, matplotlib\n",
    "* Having run 1_data_procurement.ipynb, and have the resulting csv files in the directory /data/..\n",
    "\n",
    "---\n",
    "\n",
    "## Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from globals.global_vars import url, header, coordinate_description, lat, lon, start_year, end_year, products, bands, above_below_left_right"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Land Surface Temperature (LST) \n",
    "In order to filter the pixels with questionable quality from our LST time series, we need to understand the QC bit layer. \n",
    "\n",
    "**MOD11A2** uses 8-bit unsigned integers to indicate the quality of each pixel. See the [MOD11A2](https://lpdaac.usgs.gov/products/mod11a2v061/) page for additional resources. \n",
    "\n",
    "I.e., <code>df_qc</code>, takes values ranging from 1-255:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable of interest\n",
    "var = 'lst'\n",
    "product = products[var]\n",
    "\n",
    "# Load the datasets for LST, rename, and set new index\n",
    "df_lst_data = pd.read_csv(f'data/procurement/{var}/{product}_{bands[product][0]}_{start_year}-{end_year}_{coordinate_description}.csv').rename(columns={'Unnamed: 0': 'date'}).set_index('date')\n",
    "df_lst_qc = pd.read_csv(f'data/procurement/{var}/{product}_{bands[product][1]}_{start_year}-{end_year}_{coordinate_description}.csv').rename(columns={'Unnamed: 0': 'date'}).set_index('date')\n",
    "df_lst_qc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the classification more computationaly efficient, we only want to calculate the classification of the values contained in the data.\n",
    "\n",
    "Retrieve the unique values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for unique values in df_lst_qc\n",
    "qcvals_lst = pd.unique(df_lst_qc.values.ravel())\n",
    "qcvals_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to the user-guide found at [MOD11A2](https://lpdaac.usgs.gov/products/mod11a2v061/) for the bit classifications. Note that bit 0 is the least significant bit in the table below:\n",
    "\n",
    "| Bits | Long Name | Key |\n",
    "|:--------:|:--------:|:--------|\n",
    "|  1 & 0   |  Mandatory QA flags   |  <code>00</code> = LST produced, good quality, not necessary to examine more detailed OA, <br><code>01</code>=LST produced, other quality, recommend examination of more detailed OA, <br><code>10</code>=LST not produced due to cloud effects, <br><code>11</code>=LST not produced primarily due to reasons other than cloud |\n",
    "|  3 & 2   |  Data quality flag   |  <code>00</code>=good data quality, <br><code>01</code>-other quality data,<br> <code>10</code>=TBD, <br><code>11</code>=TBD |\n",
    "|  5 & 4   |  Emis Error flag   |  <code>00</code>=average emissivity error <= 0.01, <br><code>01</code>=average emissivity error <= 0.02, <br><code>10</code>=average emissivity error <= 0.04, <br><code>11</code>=average emissivity error > 0.04   |\n",
    "|  7 & 6   |  LST Error flag   |  <code>00</code>=average LST error <= 1K <br> <code>01</code>=average LST error <= 2K, <br> <code>10</code>=average LST error <= 3K, <br> <code>11</code>=average LST error > 3K   |\n",
    "\n",
    "(The following features will not be provided with a table as above, instead, refer to the user manuals.)\n",
    "\n",
    "Now we can decide which QC filtering criteria satisfy our needs. In this study, we will filter using two levels of restrictions:\n",
    "\n",
    "More restricted filtering:\n",
    "* Pixels that were not produced (cload cover or other reason)\n",
    "* Pixels of 'other quality' that have an LST error > 2K\n",
    "\n",
    "Less restricted filtering:\n",
    "* Pixels that were not produced (cload cover or other reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_qc_data: list = []\n",
    "\n",
    "# Iterate through the list of 8-bit integers and populate QC table with bit definitions \n",
    "for integer in qcvals_lst:\n",
    "    bits = list(map(int, list(\"{0:b}\".format(integer).zfill(8))))\n",
    "    \n",
    "    # Describe each of the bits. Remember bits are big endian so bits[7] == bit 0\n",
    "    # Mandatory_QA bits description\n",
    "    if (bits[6] == 0 and bits[7] == 0):\n",
    "        Mandatory_QA = 'LST GOOD'\n",
    "    if (bits[6] == 0 and bits[7] == 1):\n",
    "        Mandatory_QA = 'LST Produced,Other Quality'\n",
    "    if (bits[6] == 1 and bits[7] == 0):\n",
    "        Mandatory_QA = 'No Pixel,clouds'\n",
    "    if (bits[6] == 1 and bits[7] == 1):\n",
    "        Mandatory_QA = 'No Pixel, Other QA'\n",
    "        \n",
    "    # Data_Quality bits description\n",
    "    if (bits[4] == 0 and bits[5] == 0):\n",
    "        Data_Quality = 'Good Data'\n",
    "    if (bits[4] == 0 and bits[5] == 1):\n",
    "        Data_Quality = 'Other Quality'\n",
    "    if (bits[4] == 1 and bits[5] == 0):\n",
    "        Data_Quality = 'TBD'\n",
    "    if (bits[4] == 1 and bits[5] == 1):\n",
    "        Data_Quality = 'TBD'\n",
    "        \n",
    "    # Emiss_Err bits description\n",
    "    if (bits[2] == 0 and bits[3] == 0):\n",
    "        Emiss_Err = 'Emiss Err <= .01'\n",
    "    if (bits[2] == 0 and bits[3] == 1):\n",
    "        Emiss_Err = 'Emiss Err <= .02'\n",
    "    if (bits[2] == 1 and bits[3] == 0):\n",
    "        Emiss_Err = 'Emiss Err <= .04'\n",
    "    if (bits[2] == 1 and bits[3] == 1):\n",
    "        Emiss_Err = 'Emiss Err > .04'\n",
    "        \n",
    "    # LST_Err bits description\n",
    "    if (bits[0] == 0 and bits[1] == 0):\n",
    "        LST_Err = 'LST Err <= 1K'\n",
    "    if (bits[0] == 0 and bits[1] == 1):\n",
    "        LST_Err = 'LST Err <= 2K'\n",
    "    if (bits[0] == 1 and bits[1] == 0):\n",
    "        LST_Err = 'LST Err <= 3K'\n",
    "    if (bits[0] == 1 and bits[1] == 1):\n",
    "        LST_Err = 'LST Err > 3K' \n",
    "    \n",
    "    # Append this integers bit values and descriptions to list\n",
    "    lst_qc_data.append([integer] + bits + [Mandatory_QA, Data_Quality, Emiss_Err, LST_Err])\n",
    "    \n",
    "# Convert QC bits and descriptions to pandas data frame\n",
    "lst_qc_data = pd.DataFrame(lst_qc_data, columns=['Integer_Value', 'Bit7', 'Bit6', 'Bit5', 'Bit4', 'Bit3', 'Bit2', 'Bit1', 'Bit0', 'Mandatory_QA', 'Data_Quality', 'Emiss_Err', 'LST_Err'])\n",
    "lst_qc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the filters as a pandas-mask.\n",
    "lst_qc_data_hard = lst_qc_data.loc[lst_qc_data['Integer_Value'].isin([2,3]) | ((lst_qc_data['Bit0'] == 1) & (lst_qc_data['Bit1'] == 0) & (lst_qc_data['Bit6'] != 0))]\n",
    "lst_qc_data_loose = lst_qc_data.loc[lst_qc_data['Integer_Value'].isin([2,3])]\n",
    "\n",
    "lst_qc_data_hard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the **pandas** function **mask()** to filter the remaining QC integer values from our LST time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the filters\n",
    "filter_hard = lst_qc_data_hard['Integer_Value'].tolist()\n",
    "filter_loose = lst_qc_data_loose['Integer_Value'].tolist()\n",
    "\n",
    "lst_data_filt_hard = df_lst_data.mask(df_lst_qc.isin(filter_hard))\n",
    "lst_data_filt_loose = df_lst_data.mask(df_lst_qc.isin(filter_loose))\n",
    "\n",
    "lst_data_filt_hard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the lengths of the dataframes\n",
    "lst_data_points = 40401* len(df_lst_data.index)\n",
    "lst_hard_filtering: int = sum(lst_data_filt_hard.isna().sum())\n",
    "lst_loose_filtering: int = sum(lst_data_filt_loose.isna().sum())\n",
    "\n",
    "print(f\"\"\"\n",
    "FILTERING EFFECT\n",
    "------------------------------------------\n",
    "number of original datapoints:      {lst_data_points}\n",
    "percentage of datapoints removed: \n",
    "    loose:                          {round(100*lst_loose_filtering/lst_data_points, 2)}%\n",
    "    hard:                           {round(100*lst_hard_filtering/lst_data_points, 2)}%\n",
    "\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the scale factor for LST (0.02). We can retrieve the scale factor from a new subset request using the same global variables as the actual data request. The unit is Kelvin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arbitrary date, included by the product\n",
    "date = 'A2010001'\n",
    "\n",
    "# Join LST request parameters to URL string and submit request\n",
    "response = requests.get(\"\".join([\n",
    "    url, products['lst'], \"/subset?\",\n",
    "    \"latitude=\", str(lat),\n",
    "    \"&longitude=\", str(lon),\n",
    "    \"&band=\", str(bands[products['lst']][0]),\n",
    "    \"&startDate=\", str(date),\n",
    "    \"&endDate=\", str(date),\n",
    "    \"&kmAboveBelow=\", str(above_below_left_right),\n",
    "    \"&kmLeftRight=\", str(above_below_left_right)\n",
    "]), headers=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, scale the dataframes using the meta-file with the response.\n",
    "scale = json.loads(response.text)['scale']\n",
    "lst_data_filt_scale_hard = lst_data_filt_hard*float(scale)\n",
    "lst_data_filt_scale_loose = lst_data_filt_loose*float(scale)\n",
    "\n",
    "lst_data_filt_scale_hard.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Land Surface Reflectance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable of interest\n",
    "var = 'lsr'\n",
    "product = products[var]\n",
    "\n",
    "# Load the datasets for LST, rename, and set new index\n",
    "df_nir = pd.read_csv(f'data/procurement/{var}/{product}_{bands[product][0]}_{start_year}-{end_year}_{coordinate_description}.csv').rename(columns={'Unnamed: 0': 'date'}).set_index('date')\n",
    "df_swir = pd.read_csv(f'data/procurement/{var}/{product}_{bands[product][1]}_{start_year}-{end_year}_{coordinate_description}.csv').rename(columns={'Unnamed: 0': 'date'}).set_index('date')\n",
    "df_lsr_qc = pd.read_csv(f'data/procurement/{var}/{product}_{bands[product][2]}_{start_year}-{end_year}_{coordinate_description}.csv').rename(columns={'Unnamed: 0': 'date'}).set_index('date')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to filter the pixels with questionable quality from our LSR time series, we need to understand the QC bit layer. \n",
    "\n",
    "**MOD09A1** uses 32-bit unsigned integers to indicate the quality of each pixel. See the [MOD09A1](https://lpdaac.usgs.gov/products/mod09a1v061/) page for additional resources. \n",
    "\n",
    "I.e., <code>df_qc</code>, takes values ranging from 0-4,294,967,295:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lsr_qc.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to see the unique values in the data. Only these will be classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique values of df_lsr_qc\n",
    "qcvals_lsr = pd.unique(df_lsr_qc.values.ravel())\n",
    "qcvals_lsr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a table describing the bits for the unique QC 16-bit integer values contained in <code>df_qc</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty list to store QC bit information\n",
    "lsr_qc_data: list  = []\n",
    "\n",
    "# Iterate through the list of 8-bit integers and populate QC table with bit definitions \n",
    "for integer in qcvals_lsr:\n",
    "    bits = list(map(int, list(\"{0:b}\".format(integer).zfill(32))))\n",
    "    \n",
    "    # Describe each of the bits. Remember bits are big endian so bits[31] == bit 0\n",
    "    \n",
    "    # MODLAND QA bits\n",
    "    if (bits[30] == 0 and bits[31] == 0):\n",
    "        produced = 'ideal quality'\n",
    "    if (bits[30] == 0 and bits[31] == 1):\n",
    "        produced = 'less than ideal quality'\n",
    "    if bits[30] == 1:\n",
    "        produced = 'not produced'\n",
    "\n",
    "    # -------------------------\n",
    "    # Specific for the NIR band\n",
    "    # -------------------------\n",
    "    \n",
    "    # band 1 data quality, four bit range\n",
    "    if (bits[22] == 0 and bits[23] == 0 and bits[24] == 0 and bits[25] == 0):\n",
    "        nir_quality = 'highest quality'\n",
    "    if not (bits[22] == 0 and bits[23] == 0 and bits[24] == 0 and bits[25] == 0):\n",
    "        nir_quality = 'insufficient quality'\n",
    "\n",
    "    # --------------------------\n",
    "    # Specific for the SWIR band\n",
    "    # --------------------------\n",
    "    \n",
    "    # band 1 data quality, four bit range\n",
    "    if (bits[6] == 0 and bits[7] == 0 and bits[8] == 0 and bits[9] == 0):\n",
    "        swir_quality = 'highest quality'\n",
    "    if not (bits[6] == 0 and bits[7] == 0 and bits[8] == 0 and bits[9] == 0):\n",
    "        swir_quality = 'insufficient quality'\n",
    "\n",
    "\n",
    "    # Append this integers bit values and descriptions to list\n",
    "    lsr_qc_data.append([integer] + [produced, nir_quality, swir_quality])\n",
    "    \n",
    "\n",
    "# Convert QC bits and descriptions to pandas data frame\n",
    "lsr_qc_data = pd.DataFrame(lsr_qc_data, columns=['integer_value', 'produced', 'nir_quality', 'swir_quality'])\n",
    "lsr_qc_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can decide which QC filtering criteria satisfy our needs. In this study, we will filter using only one filtering criteria:\n",
    "\n",
    "* When the datpoints where not correctly produced\n",
    "* When the quality is not the \"highest\"\n",
    "\n",
    "Subset the QC table again to include only rows that represent QC criteria for pixels that we want to filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the filtering criteria.\n",
    "lsr_qc_data = lsr_qc_data.loc[\n",
    "                      (lsr_qc_data['nir_quality'] == 'insufficient quality') |\n",
    "                      (lsr_qc_data['swir_quality'] == 'insufficient quality') ]\n",
    "\n",
    "lsr_qc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_refl = lsr_qc_data['integer_value'].tolist()\n",
    "\n",
    "# Define the filter as a pandas-mask.\n",
    "nir_data_filt = df_nir.mask(df_lsr_qc.isin(filter_refl))\n",
    "swir_data_filt = df_swir.mask(df_lsr_qc.isin(filter_refl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nir.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the lengths of the dataframes\n",
    "lsr_data_points = 160800* len(df_nir.index)\n",
    "lsr_filtering: int = sum(nir_data_filt.isna().sum())\n",
    "\n",
    "print(f\"\"\"\n",
    "FILTERING EFFECT\n",
    "------------------------------------------\n",
    "number of original datapoints:      {lsr_data_points}\n",
    "percentage of datapoints removed:   {round(100*lsr_filtering/lsr_data_points, 3)}%\n",
    "\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the scale factor for LSR. We can retrieve the scale factor from a new subset request using the same global variables as the actual data request. The unit is percentage of reflectance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arbitrary date, included by the product\n",
    "date = 'A2010001'\n",
    "\n",
    "# Join LST request parameters to URL string and submit request\n",
    "response = requests.get(\"\".join([\n",
    "    url, products['lsr'], \"/subset?\",\n",
    "    \"latitude=\", str(lat),\n",
    "    \"&longitude=\", str(lon),\n",
    "    \"&band=\", str(bands[products['lsr']][0]),\n",
    "    \"&startDate=\", str(date),\n",
    "    \"&endDate=\", str(date),\n",
    "    \"&kmAboveBelow=\", str(above_below_left_right),\n",
    "    \"&kmLeftRight=\", str(above_below_left_right)\n",
    "]), headers=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = json.loads(response.text)['scale']\n",
    "\n",
    "# Finally: Scaling the data frames\n",
    "nir_data_filt_scale_hard = nir_data_filt*float(scale)\n",
    "swir_data_filt_scale_hard = swir_data_filt*float(scale)\n",
    "\n",
    "nir_data_filt_scale_hard.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable of interest\n",
    "var = 'evi'\n",
    "product = products[var]\n",
    "\n",
    "# Load the datasets for LST, rename, and set new index\n",
    "df_evi_data = pd.read_csv(f'data/procurement/{var}/{product}_{bands[product][0]}_{start_year}-{end_year}_{coordinate_description}.csv').rename(columns={'Unnamed: 0': 'date'}).set_index('date')\n",
    "df_evi_qc = pd.read_csv(f'data/procurement/{var}/{product}_{bands[product][1]}_{start_year}-{end_year}_{coordinate_description}.csv').rename(columns={'Unnamed: 0': 'date'}).set_index('date')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will filter the EVI dataset.\n",
    "\n",
    "**MOD13Q1** uses 16-bit unsigned integers to indicate the quality of each pixel. See the [MOD13Q1](https://lpdaac.usgs.gov/products/MOD13Q1v061/) page for additional resources.\n",
    "\n",
    "I.e., <code>df_qc</code>, takes values ranging from 0-65535:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evi_qc.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the classification more computationaly efficient, we only want to calculate the classification of the values contained in the data.\n",
    "\n",
    "Retrieve the unique values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of all the unique values in df_evi_qc\n",
    "qcvals_evi = pd.unique(df_evi_qc.values.ravel())\n",
    "len(qcvals_evi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a table describing the bits of interest for the unique QC 16-bit integer values contained in <code>df_evi_qc</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty list to store QC bit information\n",
    "evi_qc_data = []\n",
    "vi_quality = 0\n",
    "vi_usefulness = 0\n",
    "# Iterate through the list of 8-bit integers and populate QC table with bit definitions \n",
    "for integer in qcvals_evi:\n",
    "    bits = list(map(int, list(\"{0:b}\".format(integer).zfill(16))))\n",
    "    \n",
    "    # Describe each of the bits. Remember bits are small endian so bit[0] == bit 0\n",
    "    # VI Quality\n",
    "    if (bits[0] == 0 and bits[1] == 0):\n",
    "        vi_quality = 'VI produced with good quality'\n",
    "    if (bits[0] == 0 and bits[1] == 1):\n",
    "        vi_quality = 'VI produced, but check other QA'\n",
    "    if (bits[0] == 1 and bits[1] == 0):\n",
    "        vi_quality = 'Pixel produced, but most probably cloudy'\n",
    "    if (bits[0] == 1 and bits[1] == 1):\n",
    "        vi_quality = 'Pixel not produced due to other reasons than clouds'\n",
    "        \n",
    "    # VI Usefulness\n",
    "    if (bits[2] == 0 and bits[3] == 0 and bits[4] == 0 and bits[5] == 0):\n",
    "        vi_usefulness = 'Highest quality'\n",
    "    if (bits[2] == 0 and bits[3] == 0 and bits[4] == 0 and bits[5] == 1):\n",
    "        vi_usefulness = 'Lower quality'\n",
    "    if (bits[2] == 0 and bits[3] == 0 and bits[4] == 1 and bits[5] == 0):\n",
    "        vi_usefulness = 'Decreasing quality'\n",
    "    if (bits[2] == 0 and bits[3] == 1 and bits[4] == 0 and bits[5] == 0):\n",
    "        vi_usefulness = 'Decreasing quality'\n",
    "    if (bits[2] == 1 and bits[3] == 0 and bits[4] == 0 and bits[5] == 0):\n",
    "        vi_usefulness = 'Decreasing quality'\n",
    "    if (bits[2] == 1 and bits[3] == 0 and bits[4] == 0 and bits[5] == 1):\n",
    "        vi_usefulness = 'Decreasing quality'\n",
    "    if (bits[2] == 1 and bits[3] == 0 and bits[4] == 1 and bits[5] == 0):\n",
    "        vi_usefulness = 'Decreasing quality'\n",
    "    if (bits[2] == 1 and bits[3] == 1 and bits[4] == 0 and bits[5] == 0):\n",
    "        vi_usefulness = 'Lowest quality'\n",
    "    if (bits[2] == 1 and bits[3] == 1 and bits[4] == 0 and bits[5] == 1):\n",
    "        vi_usefulness = 'Quality so low that it is not useful'\n",
    "    if (bits[2] == 1 and bits[3] == 1 and bits[4] == 1 and bits[5] == 0):\n",
    "        vi_usefulness = 'L1B data faulty'\n",
    "    if (bits[2] == 1 and bits[3] == 1 and bits[4] == 1 and bits[5] == 1):\n",
    "        vi_usefulness = 'Not useful for any other reason/not processed'\n",
    "    \n",
    "\n",
    "    # Append this integers bit values and descriptions to list\n",
    "    evi_qc_data.append([integer] + [vi_quality, vi_usefulness])\n",
    "    \n",
    "\n",
    "# Convert QC bits and descriptions to pandas data frame\n",
    "evi_qc_data = pd.DataFrame(evi_qc_data, columns=['integer_value', 'vi_quality', 'vi_usefulness'])\n",
    "evi_qc_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can decide which QC filtering criteria satisfy our needs. In this study, we will filter using two levels of restrictions.\n",
    "\n",
    "More restricted filtering:\n",
    "* Pixel produced, but most probably cloudy\n",
    "* Pixels that were not produced due to other reasons than clouds\n",
    "* Lowest quality of pixel\n",
    "* Pixels of 'quality so low that it is not useful', 'not useful for any other reason/not processed', 'L1B data faulty'\n",
    "\n",
    "Less restricted filtering\n",
    "* Pixels that were not produced due to other reasons than clouds\n",
    "* Pixels of 'quality so low that it is not useful', 'not useful for any other reason/not processed', 'L1B data faulty'\n",
    "\n",
    "Subset the QC table again to include only rows that represent QC criteria for pixels that we want to filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the filtering criteria\n",
    "evi_qc_data_hard = evi_qc_data.loc[(evi_qc_data['vi_quality'] == 'Pixel produced, but most probably cloudy') |\n",
    "                                (evi_qc_data['vi_quality'] == 'Pixel not produced due to other reasons than clouds') | \n",
    "                                (evi_qc_data['vi_usefulness'] == 'Lowest quality') |\n",
    "                                (evi_qc_data['vi_usefulness'] == 'Quality so low that it is not useful') |\n",
    "                                (evi_qc_data['vi_usefulness'] == 'L1B data faulty') |\n",
    "                                (evi_qc_data['vi_usefulness'] == 'Not useful for any other reason/not processed')]   \n",
    "\n",
    "evi_qc_data_loose = evi_qc_data.loc[(evi_qc_data['vi_quality'] == 'Pixel not produced due to other reasons than clouds') | \n",
    "                                (evi_qc_data['vi_usefulness'] == 'Quality so low that it is not useful') |\n",
    "                                (evi_qc_data['vi_usefulness'] == 'L1B data faulty') |\n",
    "                                (evi_qc_data['vi_usefulness'] == 'Not useful for any other reason/not processed')] \n",
    "                                \n",
    "evi_qc_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the **pandas** function **mask()** to filter the remaining QC integer values from our EVI time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the filtering as a pandas-mask.\n",
    "filter_hard = evi_qc_data_hard['integer_value'].tolist()\n",
    "filter_loose = evi_qc_data_loose['integer_value'].tolist()\n",
    "\n",
    "evi_data_filt_hard = df_evi_data.mask(df_evi_qc.isin(filter_hard))\n",
    "evi_data_filt_loose = df_evi_data.mask(df_evi_qc.isin(filter_loose))\n",
    "\n",
    "evi_data_filt_hard.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the scale factor for EVI (0.0001)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the lengths of the dataframes\n",
    "evi_data_points = 641600* len(df_evi_data.index)\n",
    "evi_filtering_h: int = sum(evi_data_filt_hard.isna().sum())\n",
    "evi_filtering_l: int = sum(evi_data_filt_loose.isna().sum())\n",
    "\n",
    "print(f\"\"\"\n",
    "FILTERING EFFECT\n",
    "------------------------------------------\n",
    "number of original datapoints:      {lsr_data_points}\n",
    "percentage of datapoints removed:   \n",
    "    hard:                           {round(100*evi_filtering_h/evi_data_points, 2)}%\n",
    "    loose:                          {round(100*evi_filtering_l/evi_data_points, 2)}%\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, scale the dataframes.\n",
    "scale = 0.0001\n",
    "evi_data_filt_scale_hard = evi_data_filt_hard*float(scale)\n",
    "evi_data_filt_scale_loose = evi_data_filt_loose*float(scale)\n",
    "\n",
    "evi_data_filt_scale_hard.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fire detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable of interest\n",
    "var = 'fire'\n",
    "product = products[var]\n",
    "\n",
    "# Load the datasets for LST, rename, and set new index\n",
    "df_fire_data = pd.read_csv(f'data/procurement/{var}/{product}_{bands[product][0]}_{start_year}-{end_year}_{coordinate_description}.csv').rename(columns={'Unnamed: 0': 'date'}).set_index('date')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although there is a QC data-set for the MOD14A2 product, also the FireMask band contains the data of interest.\n",
    "\n",
    "The data is stored as an integers scheme ranging from 0-10:\n",
    "\n",
    "- 0: not processed (missing input data)\n",
    "- 1: not processed (obsolete; not used since Collection 1)\n",
    "- 2: not processed (other reason)\n",
    "- 3: non-fire water pixel\n",
    "- 4: cloud (land or water)\n",
    "- 5: non-fire land pixel\n",
    "- 6: unknown (land or water)\n",
    "- 7: fire (low confidence, land or water)\n",
    "- 8: fire (nominal confidence, land or water)\n",
    "- 9: fire (high confidence, land or water)\n",
    "\n",
    "\n",
    "We can directly decide which filtering criteria satisfy our needs. In this study, we will filter:\n",
    "\n",
    "* When the pixel is not processed (0-2)\n",
    "* When the data is over water (3)\n",
    "* When there is cloud (4)\n",
    "* When the value is unknown (6)\n",
    "\n",
    "Subset the QC table again to include only rows that represent QC criteria for pixels that we want to filter:\n",
    "See the [MOD14A2](https://lpdaac.usgs.gov/products/mod14a2v061/) page for additional resources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the data\n",
    "df_fire_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the **pandas** function **mask()** to filter the remaining QC integer values from our LSR time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two different filters, although they are the same, for more convenience later (the differentiation happens later)\n",
    "filter_hard = [0, 1, 2, 3, 4, 6]\n",
    "filter_loose = [0, 1, 2, 3, 4, 6]\n",
    "\n",
    "fire_data_filt_hard = df_fire_data.mask(df_fire_data.isin(filter_hard))\n",
    "fire_data_filt_loose = df_fire_data.mask(df_fire_data.isin(filter_loose))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the lengths of the dataframes\n",
    "fire_data_points = 40400* len(df_fire_data.index)\n",
    "fire_filtering_h: int = sum(fire_data_filt_hard.isna().sum())\n",
    "fire_filtering_l: int = sum(fire_data_filt_loose.isna().sum())\n",
    "\n",
    "print(f\"\"\"\n",
    "FILTERING EFFECT\n",
    "------------------------------------------\n",
    "number of original datapoints:      {lsr_data_points}\n",
    "percentage of datapoints removed:   \n",
    "    hard:                           {round(100*fire_filtering_h/fire_data_points, 2)}%\n",
    "    loose:                          {round(100*fire_filtering_l/fire_data_points, 2)}%\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire_data_filt_hard.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save filtered data in csv files, in either data/filtered/hard or data/filtered/loose\n",
    "\n",
    "# LST\n",
    "lst_data_filt_scale_hard.to_csv(f'data/filtered/hard/lst_{start_year}-{end_year}_{coordinate_description}.csv')\n",
    "lst_data_filt_scale_loose.to_csv(f'data/filtered/loose/lst_{start_year}-{end_year}_{coordinate_description}.csv')\n",
    "\n",
    "# NIR & SWIR\n",
    "nir_data_filt_scale_hard.to_csv(f'data/filtered/hard/nir_{start_year}-{end_year}_{coordinate_description}.csv')\n",
    "swir_data_filt_scale_hard.to_csv(f'data/filtered/hard/swir_{start_year}-{end_year}_{coordinate_description}.csv')\n",
    "\n",
    "# EVI\n",
    "evi_data_filt_scale_hard.to_csv(f'data/filtered/hard/evi_{start_year}-{end_year}_{coordinate_description}.csv')\n",
    "evi_data_filt_scale_loose.to_csv(f'data/filtered/loose/evi_{start_year}-{end_year}_{coordinate_description}.csv')\n",
    "\n",
    "# FIRE\n",
    "fire_data_filt_hard.to_csv(f'data/filtered/hard/fire_{start_year}-{end_year}_{coordinate_description}.csv')\n",
    "fire_data_filt_loose.to_csv(f'data/filtered/loose/fire_{start_year}-{end_year}_{coordinate_description}.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap-up\n",
    "Now you should have filtered the datasets.\n",
    "\n",
    "Have a nice day!\n",
    "\n",
    "/ Alicia"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rise-wildfires",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
