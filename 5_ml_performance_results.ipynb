{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Machine Learning Methods\n",
    " \n",
    "*Date: July 31, 2023*  \n",
    "*Author: Alicia Larsen*     \n",
    "*Institution: The Research Institute of Sweden (RISE)*   \n",
    "*Contact: alicia.hh.larsen@gmail.com*   \n",
    "\n",
    "This is the 6th notebook of 7, in the series \"RISE Wildfire Prediction Using Machine Learning\"\n",
    "\n",
    "References: This notebook is based on the procedures in the notebook found on this [link](https://github.com/ornldaac/modis_restservice_qc_filter_Python/blob/master/modis_restservice_qc_filter_Python.ipynb). This notebook can also be found in /initial-eda/data-procurement/reference-notebook/download-modis-data-example-notebook.ipynb, on github.com:larsenalicia/RISE-wildfire-prediction.git\n",
    "\n",
    "##### Keywords: LST, LSR, Fire, MODIS, Python\n",
    "\n",
    "## Overview\n",
    "This notebook will explore different prediction models and datasets using:\n",
    "- Linear Regression\n",
    "- Random forest\n",
    "- Support Vector Machines (SVM)\n",
    "\n",
    "## Prerequisites: \n",
    "\n",
    "* Python 2 or 3   \n",
    "* Libraries: requests, json, datetime, pandas, numpy, matplotlib\n",
    "---\n",
    "\n",
    "## Set-up\n",
    "### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import 'LogisticRegression' and create a LogisticRegression object\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import 'RandomForestRegressor'\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Import modules to visualise the random forest\n",
    "from sklearn.tree import export_graphviz\n",
    "# import pydot\n",
    "\n",
    "# Import Support vector machine\n",
    "from sklearn import svm\n",
    "\n",
    "# Import for Cross validation\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "from globals.global_vars import url, header, coordinate_description, lat, lon, start_year, end_year, products, bands, random_state, product_names\n",
    "from procerdures.d_model import performace_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "test_size = 0.33\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes: dict = {}\n",
    "\n",
    "# Iterate through the different frequences\n",
    "for frequency in ['least', 'most']:\n",
    "\n",
    "    # Iterate through the different filtering restrictions\n",
    "    for restriction in ['hard', 'loose']:\n",
    "\n",
    "        for size in ['largest', 'middle', 'smallest']:\n",
    "\n",
    "            # Read a CSV in the right directory\n",
    "            df_data = pd.read_csv(f'data/aggregation/normalized/alldata_{frequency}_{restriction}_{size}_{start_year}-{end_year}_{coordinate_description}.csv')\n",
    "\n",
    "            # Add the dataframe to a dictionary, for access\n",
    "            dataframes[f'{frequency}_{restriction}_{size}'] = df_data.rename(columns={'Unnamed: 0': 'date'}).set_index(['date', 'pixel'])\n",
    "\n",
    "# Take a look at the keys\n",
    "dataframes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the structure at an arbitrary dataframe (they lall look the same)\n",
    "dataframes['least_loose_largest'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the dataframe-identifiers\n",
    "for key in dataframes:\n",
    "    series = dataframes[key]['fire']\n",
    "    print(key, series.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataframe\n",
    "df_data = dataframes['least_hard_largest']\n",
    "\n",
    "# Define the features and targets\n",
    "X = df_data[['temperature_k', 'ndmi', 'evi']].values\n",
    "y = df_data['fire'].values\n",
    "\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)\n",
    "\n",
    "# Initialize the models, and store them in a list for iterable access\n",
    "lr = LogisticRegression(random_state=random_state)\n",
    "rf = RandomForestRegressor(n_estimators = 50, random_state = random_state)\n",
    "clf = svm.SVC(random_state=random_state)\n",
    "models = [lr, rf, clf]\n",
    "trained_models = []\n",
    "validations_lst = []\n",
    "\n",
    "# Iterate through the models: train them and look at the true/false positives/negatives.\n",
    "for model in models:\n",
    "    trained_model, df_validation = performace_matrix(model, X_train, X_test, y_train, y_test)\n",
    "    trained_models.append(trained_model)\n",
    "    validations_lst.append(df_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation = pd.DataFrame(columns = ['frequency', 'restriction', 'size', 'model', 'true_negative', 'false_positive', 'false_negative', 'true_positive'])\n",
    "\n",
    "# Iterate through the models\n",
    "for i, validation_model in enumerate(validations_lst):\n",
    "\n",
    "    # Define necessary componants\n",
    "    key_lst = key.split('_')\n",
    "    row: dict = {}\n",
    "\n",
    "    # Define the values at each position in the dictionary, later: at each column per row in dataframe \n",
    "    row['frequency'] = key_lst[0]\n",
    "    row['restriction'] = key_lst[1]\n",
    "    row['size'] = key_lst[2]\n",
    "    \n",
    "    if i == 0:\n",
    "        row['model'] = 'LR'\n",
    "    elif i == 1:\n",
    "        row['model'] = 'RF'\n",
    "    elif i == 2:\n",
    "        row['model'] = 'SVM'\n",
    "\n",
    "    row['true_negative'] = validation_model.loc['Negative', 'predicted_negative'] / (validation_model.sum()).sum()\n",
    "    row['false_positive'] = validation_model.loc['Negative', 'predicted_positive'] / (validation_model.sum()).sum()\n",
    "    row['false_negative'] = validation_model.loc['Positive', 'predicted_negative'] / (validation_model.sum()).sum()\n",
    "    row['true_positive'] = validation_model.loc['Positive', 'predicted_positive'] / (validation_model.sum()).sum()\n",
    "\n",
    "    # Add the dictionary as a row, as the last row in the the dataframe\n",
    "    df_validation.loc[len(df_validation)] = row\n",
    "\n",
    "# Change the format to multi-index, and show the result\n",
    "df_validation_mi = df_validation.set_index(['frequency', 'restriction', 'size', 'model'])\n",
    "df_validation_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_per_data: dict = {}\n",
    "validations: dict = {}\n",
    "\n",
    "# Iterate through the dataframe-identifiers\n",
    "for key in dataframes:\n",
    "    print('hi')\n",
    "    # Define the dataframe, and the idenpendent and depednent variables\n",
    "    df = dataframes[key]\n",
    "    X = df[['temperature_k', 'ndmi', 'evi']].values\n",
    "    y = df['fire'].values\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)\n",
    "\n",
    "    # Initialize the models, and store them in a list for iterable access\n",
    "    lr = LogisticRegression(random_state=random_state)\n",
    "    rf = RandomForestRegressor(n_estimators = 50, random_state = random_state)\n",
    "    clf = svm.SVC(random_state=random_state)\n",
    "    models = [lr, rf, clf]\n",
    "    trained_models = []\n",
    "    validations_lst = []\n",
    "\n",
    "    # Iterate through the models: train them and look at the true/false positives/negatives.\n",
    "    for model in models:\n",
    "        trained_model, df_validation = performace_matrix(model, X_train, X_test, y_train, y_test)\n",
    "        trained_models.append(trained_model)\n",
    "        validations_lst.append(df_validation)\n",
    "\n",
    "    # Store the trained models per input data\n",
    "    models_per_data[key] = trained_models\n",
    "    validations[key] = validations_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation = pd.DataFrame(columns = ['frequency', 'restriction', 'size', 'model', 'true_negative', 'false_positive', 'false_negative', 'true_positive'])\n",
    "\n",
    "# Iterate through the lists of validation-dataframe identifiers (dictionary of list of 2x2 dataframes)\n",
    "for key in validations:\n",
    "\n",
    "    # Define the list of the validation-dataframes, per model\n",
    "    validation_lst = validations[key]\n",
    "\n",
    "    # Iterate through the models\n",
    "    for i, validation_model in enumerate(validation_lst):\n",
    "\n",
    "        # Define necessary componants\n",
    "        key_lst = key.split('_')\n",
    "        row: dict = {}\n",
    "\n",
    "        # Define the values at each position in the dictionary, later: at each column per row in dataframe \n",
    "        row['frequency'] = key_lst[0]\n",
    "        row['restriction'] = key_lst[1]\n",
    "        row['size'] = key_lst[2]\n",
    "        \n",
    "        if i == 0:\n",
    "            row['model'] = 'LR'\n",
    "        elif i == 1:\n",
    "            row['model'] = 'RF'\n",
    "        elif i == 2:\n",
    "            row['model'] = 'SVM'\n",
    "\n",
    "        row['true_negative'] = validation_model.loc['Negative', 'predicted_negative']\n",
    "        row['false_positive'] = validation_model.loc['Negative', 'predicted_positive']\n",
    "        row['false_negative'] = validation_model.loc['Positive', 'predicted_negative']\n",
    "        row['true_positive'] = validation_model.loc['Positive', 'predicted_positive']\n",
    "\n",
    "        # Add the dictionary as a row, as the last row in the the dataframe\n",
    "        df_validation.loc[len(df_validation)] = row\n",
    "\n",
    "# Change the format to multi-index, and show the result\n",
    "df_validation_mi = df_validation.set_index(['frequency', 'restriction', 'size', 'model'])\n",
    "df_validation_mi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics per data-set category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency\n",
    "df_validation_freq = df_validation_mi.groupby('frequency').mean()\n",
    "df_validation_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering restriction\n",
    "df_validation_rest = df_validation_mi.groupby('restriction').mean()\n",
    "df_validation_rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size\n",
    "df_validation_size = df_validation_mi.groupby('size').mean()\n",
    "df_validation_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model type\n",
    "df_validation_mod = df_validation_mi.groupby('model').mean()\n",
    "df_validation_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics random forest specifically, per data-set category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics for random forest\n",
    "df_validation_rf = df_validation[df_validation['model'] == 'RF']\n",
    "df_validation_rf = df_validation_mi.groupby(['frequency', 'restriction', 'size']).mean()\n",
    "df_validation_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency\n",
    "df_validation_freq = df_validation_rf.groupby('frequency').mean()\n",
    "df_validation_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering\n",
    "df_validation_rest = df_validation_rf.groupby('restriction').mean()\n",
    "df_validation_rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size\n",
    "df_validation_size = df_validation_rf.groupby('size').mean()\n",
    "df_validation_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_coefficients = pd.DataFrame(columns = ['frequency', 'restriction', 'size', 'lst', 'ndmi', 'evi'])\n",
    "\n",
    "\n",
    "# Iterate through the dictionary of lists of models, and define the list of models\n",
    "for key in models_per_data:\n",
    "    trained_models = models_per_data[key]\n",
    "\n",
    "    # Define necessary components\n",
    "    key_lst = key.split('_')\n",
    "    row: dict = {}\n",
    "\n",
    "    # Define the values at each position in the dictionary, later: at each column per row in dataframe \n",
    "    row['frequency'] = key_lst[0]\n",
    "    row['restriction'] = key_lst[1]\n",
    "    row['size'] = key_lst[2]\n",
    "\n",
    "    lr = trained_models[0]\n",
    "    row['lst'] = lr.coef_[0][0]\n",
    "    row['ndmi'] = lr.coef_[0][1]\n",
    "    row['evi'] = lr.coef_[0][2]\n",
    "\n",
    "    # Add the dictionary as a row, as the last row in the the dataframe\n",
    "    lr_coefficients.loc[len(lr_coefficients)] = row\n",
    "\n",
    "# Change the format to multi-index, and show the result\n",
    "lr_coefficients = lr_coefficients.set_index(['frequency', 'restriction', 'size'])\n",
    "lr_coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 score validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f1_validation = pd.DataFrame(columns = ['frequency', 'restriction', 'size', 'f1'])\n",
    "k_folds = 10\n",
    "\n",
    "# Iterate through the dictionary of lists of models, and define the list of models\n",
    "for key in dataframes:\n",
    "    df = dataframes[key]\n",
    "    key_lst = key.split('_')\n",
    "\n",
    "    row: dict = {}\n",
    "\n",
    "    # Define the values at each position in the dictionary, later: at each column per row in dataframe \n",
    "    row['frequency'] = key_lst[0]\n",
    "    row['restriction'] = key_lst[1]\n",
    "    row['size'] = key_lst[2]\n",
    "    \n",
    "    # Initialize the model\n",
    "    rf = RandomForestClassifier(n_estimators = 100, \n",
    "                        random_state = random_state,\n",
    "                        class_weight = {0: 0.01, 1: 0.99})\n",
    "\n",
    "    # Calculate the f1 scores\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = np.rint(rf.predict(X_test))\n",
    "    row['f1'] = f1_score(y_test, y_pred, average='binary')\n",
    "\n",
    "    # Add the dictionary as a row, as the last row in the the dataframe\n",
    "    df_f1_validation.loc[len(df_f1_validation)] = row\n",
    "\n",
    "# Change the format to multi-index, and show the result\n",
    "df_f1_validation_mi = df_f1_validation.set_index(['frequency', 'restriction', 'size'])\n",
    "df_f1_validation_mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency\n",
    "df_k_validation_freq = df_f1_validation_mi.groupby('frequency').mean()\n",
    "df_k_validation_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering\n",
    "df_k_validation_rest = df_f1_validation_mi.groupby('restriction').mean()\n",
    "df_k_validation_rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size\n",
    "df_k_validation_size = df_f1_validation_mi.groupby('size').mean()\n",
    "df_k_validation_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap-up\n",
    "Now you should know what model that performs the best.\n",
    "\n",
    "Have a nice day!\n",
    "\n",
    "/ Alicia"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rise-wildfires",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
